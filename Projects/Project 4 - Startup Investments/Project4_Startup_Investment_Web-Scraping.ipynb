{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_content(url):\n",
    "    resp=r.get(url).content\n",
    "    BeautifulSoup(resp)\n",
    "    return soup   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "def get_soup_from_selenium(url):\n",
    "    driver= webdriver.Chrome('chromedriver_win32/chromedriver')\n",
    "    driver.get(url)\n",
    "    delay = 50 # seconds\n",
    "    try:\n",
    "        WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.ID, 'search_location_state')))\n",
    "        print (\"Page is ready!\")\n",
    "        soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "    except TimeoutException:\n",
    "        print (\"Loading took too much time!\")\n",
    "    return soup\n",
    "    \n",
    "get_soup_from_selenium('https://www.startupranking.com/top/0/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_home_page(url):\n",
    "    print(url)\n",
    "    soup=get_soup_from_selenium(url)\n",
    "    tabs=soup.find_all('table',{'class':'rank_table'})[0]\n",
    "    rows=tabs.find_all('tr')\n",
    "    list_urls=[i.select('a')[0].get('href') for i in rows]\n",
    "    list_urls.pop(0)\n",
    "    return list_urls\n",
    "\n",
    "scrap_home_page('https://www.startupranking.com/top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def scrap_startup_page(url_startup,total_funding_amount):\n",
    "\n",
    "    resp2=r.get(url_startup).content\n",
    "    \n",
    "    soup2=BeautifulSoup(resp2)\n",
    "    country_name = soup2.select('img.flag')[0].get('alt')\n",
    "    name=soup2.select('div.su-info h2 a')[0].text\n",
    "    # founded date\n",
    "    tabb = soup2.select('div.su-info p.su-loc')\n",
    "    if len(tabb)==0: \n",
    "        founded_date = ''\n",
    "    else:\n",
    "        founded_date =  tabb[0].text.strip()\n",
    "    \n",
    "    cat = soup2.select('div.su-tags.group ul li')\n",
    "    category_list =[i.text for i in cat]\n",
    "    category_string = ','.join(category_list)\n",
    "    dict_info={'name':[name],'country_name':[country_name],'founded_date':[founded_date],'category_list': [category_string],'total_funding_amout':[total_funding_amount]}\n",
    "    df=pd.DataFrame(dict_info)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "scrap_startup_page('https://www.startupranking.com/ifttt',210100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_funding_page(url_startup_page):\n",
    "    resp=r.get(url_startup_page).content\n",
    "    soup=BeautifulSoup(resp)\n",
    "    tabb = soup.select('.small-table-container')[1].select('a.see-all')\n",
    "    if len(tabb)==0: \n",
    "        return ''\n",
    "    else:\n",
    "        return tabb[0].get('href')\n",
    "get_url_funding_page('https://www.startupranking.com/ifttt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_total_funding_amount(url_funding_page):\n",
    "    if url_funding_page=='':\n",
    "        return 0\n",
    "    else:\n",
    "        resp=r.get(url_funding_page).content\n",
    "        soup=BeautifulSoup(resp)\n",
    "        tabs2 = soup.select('.ranks')[0]\n",
    "        rows2=tabs2.find_all('tr')\n",
    "        list_funding_amount = [i.select('span')[0].text for i in rows2]\n",
    "        list_funding_amount = list(filter(lambda a: a != 'Undisclosed amount', list_funding_amount))\n",
    "        funding_amount_dolar = [int(re.search(r'[0-9]+',i.replace(',','')).group(0)) for i in list_funding_amount]\n",
    "        Total_funding_amount = sum(funding_amount_dolar)\n",
    "        return Total_funding_amount\n",
    "\n",
    "get_total_funding_amount('https://www.startupranking.com/startup/ifttt/funding-rounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "data = scrap_startup_page('https://www.startupranking.com/500px',0,210100000)\n",
    "def save_to_sql(data):\n",
    "    connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='safa',\n",
    "                             db='startupdb')\n",
    "    cursor = connection.cursor()\n",
    "    # creating column list for insertion\n",
    "    cols = \"`,`\".join([str(i) for i in data.columns.tolist()])\n",
    "\n",
    "    # Insert DataFrame recrds one by one.\n",
    "    for i,row in data.iterrows():\n",
    "        sql = \"INSERT INTO `startup` (`\" +cols + \"`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "        cursor.execute(sql, tuple(row))\n",
    "\n",
    "        # the connection is not autocommitted by default, so we must commit to save our changes\n",
    "        connection.commit()\n",
    "save_to_sql(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def scrap_all_startup_perpage(url_home,list_urls):\n",
    "    dataframe = pd.DataFrame()\n",
    "    i=0\n",
    "    for url_startup in list_urls:\n",
    "        i+=1\n",
    "        whole_url_startup = url_home + url_startup\n",
    "        print('url =', whole_url_startup)\n",
    "        \n",
    "        url_funding = get_url_funding_page(whole_url_startup)\n",
    "        if url_funding=='':\n",
    "            whole_url_funding = ''\n",
    "        else:\n",
    "            whole_url_funding = url_home + url_funding\n",
    "       # dataframe['total_funding_amout'] = get_total_funding_amount(whole_url_funding)\n",
    "        total = get_total_funding_amount(whole_url_funding)\n",
    "        new_df = scrap_startup_page(whole_url_startup,i,total)\n",
    "        dataframe = dataframe.append(new_df)\n",
    "        time.sleep(1)\n",
    "        if i%10==0:\n",
    "            pos = i-10\n",
    "            print(f'dataframe.iloc[{pos},{i}]')\n",
    "            df = dataframe.iloc[pos:i]\n",
    "            save_to_sql(df)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "url = 'https://www.startupranking.com/top'\n",
    "url_home = 'https://www.startupranking.com'\n",
    "list_urls = scrap_home_page(url)\n",
    "dataframe = scrap_all_startup_perpage(url_home,list_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_startup_page(n,url_home,url_top):\n",
    "    dataframe = pd.DataFrame()\n",
    "    for i in range(int(n)):\n",
    "        url_new = url_top+'/'+str(i+1)\n",
    "        list_urls = scrap_home_page(url_new)\n",
    "        df = scrap_all_startup_perpage(url_home,list_urls)\n",
    "        dataframe = dataframe.append(df)     \n",
    "    dataframe.to_csv('startup2.csv')\n",
    "    return dataframe\n",
    "\n",
    "dataframe2 = iterate_startup_page('2','https://www.startupranking.com','https://www.startupranking.com/top/0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
